# Faiss indekslerini temizleme ve hafÄ±zayÄ± boÅŸaltma iÃ§in zamanlama
def clean_faiss_indexes_periodically():
    """DÃ¼zenli aralÄ±klarla Faiss indekslerini sÄ±fÄ±rla ve hafÄ±zayÄ± temizle"""
    global faiss_indexes, cached_features, cached_filenames, cached_metadata
    
    # Belirli bir sÃ¼re geÃ§tikten sonra temizlik yap
    print("ğŸ•“ PlanlÄ± Faiss indeks temizliÄŸi baÅŸlatÄ±lÄ±yor")
    
    # Faiss indekslerini sÄ±fÄ±rla
    faiss_indexes = {}
    
    # Ã–ncelikle Ã¶zellik vektÃ¶rleri dÄ±ÅŸÄ±ndaki Ã¶nbellekleri sÄ±fÄ±rla
    cached_filenames = {}
    cached_metadata = None
    
    # Bellek toplama iÅŸlemini manuel olarak baÅŸlat
    gc.collect()
    
    # Bir sonraki planlÄ± temizliÄŸi zamanla (4 saat sonra)
    timer = threading.Timer(4 * 60 * 60, clean_faiss_indexes_periodically)  # 4 saat
    timer.daemon = True  # Program kapanÄ±rken thread'in kapanmasÄ±nÄ± saÄŸla
    timer.start()# app.py
# OluÅŸturulma: 2025-04-19
# HazÄ±rlayan: Kafkas
# AÃ§Ä±klama:
# Bu Flask uygulamasÄ±, Power User (PU) arayÃ¼zÃ¼yle etkileÅŸime girer.
# KullanÄ±cÄ±lara metadata gÃ¼ncelleme, model eÄŸitimi ve feedback sistemlerini yÃ¶netme imkÃ¢nÄ± saÄŸlar.
# Åu an aktif olan endpointler:
# - "/"              â†’ Ana yÃ¶nlendirme (ileride dashboard'a baÄŸlanabilir)
# - "/train"         â†’ EÄŸitim arayÃ¼zÃ¼ (train.html)
# - "/train-model"   â†’ POST ile eÄŸitim baÅŸlatma
# - "/check-updates" â†’ JSON & gÃ¶rsel gÃ¼ncellemelerini kontrol eder
# - "/find-similar"  â†’ Benzer desen gÃ¶rsellerini getirir
# - "/realImages/<path:filename>" â†’ GerÃ§ek gÃ¶rselleri sunar
# - "/create-cluster" â†’ SeÃ§ilen gÃ¶rsellerle yeni cluster oluÅŸturur

from flask import Flask, render_template, request, jsonify, send_from_directory
from train_handlers import setup_training_routes
import json
import subprocess
import sys
import os
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances
import shutil
from datetime import datetime
import random
import traceback
import faiss  # Faiss kÃ¼tÃ¼phanesini ekledik
import colorsys  # Renk dÃ¶nÃ¼ÅŸÃ¼mleri iÃ§in eklendi
import cv2
import threading
import gc
import time  # time modÃ¼lÃ¼nÃ¼ eksikti

# SÃ¼rÃ¼m bilgisi
APP_VERSION = "1.2.0"
APP_LAST_UPDATED = "2025-04-28"

app = Flask(__name__)

# Faiss indekslerini saklamak iÃ§in global deÄŸiÅŸken
faiss_indexes = {}

# Ã–zellik vektÃ¶rlerini ve dosya isimlerini saklamak iÃ§in global deÄŸiÅŸkenler
cached_features = {}
cached_filenames = {}
cached_metadata = None

# Faiss indeksi oluÅŸturma ve alÄ±m iÃ§in yardÄ±mcÄ± fonksiyon
def get_faiss_index(model_type):
    """Belirtilen model tipi iÃ§in Faiss indeksi oluÅŸturur veya Ã¶nbellekten alÄ±r"""
    # Ã–nbellekte varsa dÃ¶ndÃ¼r
    if model_type in faiss_indexes:
        return faiss_indexes[model_type]
    
    # Ã–nbellekte yoksa yÃ¼kle
    feature_path = f"image_features/{model_type}_features.npy"
    if not os.path.exists(feature_path):
        return None
    
    # Ã–zellik vektÃ¶rlerini yÃ¼kle (Ã¶nbellekte yoksa)
    if model_type not in cached_features:
        features = np.load(feature_path)
        cached_features[model_type] = features.astype(np.float32)
    else:
        features = cached_features[model_type]
    
    # Faiss indeksi oluÅŸtur
    d = features.shape[1]  # VektÃ¶r boyutu
    
    # GPU kontrolÃ¼
    use_gpu = faiss.get_num_gpus() > 0
    
    if model_type in ["pattern", "color+pattern"] or model_type.startswith("pattern"):
        # KosinÃ¼s benzerliÄŸi iÃ§in L2 normalleÅŸtirme
        normalized_features = features.copy()
        faiss.normalize_L2(normalized_features)
        
        if use_gpu:
            # GPU ile IP (Inner Product) indeksi
            print(f"ğŸš€ {model_type} iÃ§in GPU ile Faiss IP indeksi oluÅŸturuluyor")
            flat_config = faiss.GpuIndexFlatConfig()
            flat_config.device = 0
            res = faiss.StandardGpuResources()
            index = faiss.GpuIndexFlatIP(res, d, flat_config)
        else:
            # CPU ile IP indeksi
            print(f"ğŸ“Š {model_type} iÃ§in CPU ile Faiss IP indeksi oluÅŸturuluyor")
            index = faiss.IndexFlatIP(d)
        
        # Normalize edilmiÅŸ vektÃ¶rleri ekle
        index.add(normalized_features)
    else:
        # Ã–klid mesafesi iÃ§in L2 indeksi
        if use_gpu:
            print(f"ğŸš€ {model_type} iÃ§in GPU ile Faiss L2 indeksi oluÅŸturuluyor")
            flat_config = faiss.GpuIndexFlatConfig()
            flat_config.device = 0
            res = faiss.StandardGpuResources()
            index = faiss.GpuIndexFlatL2(res, d, flat_config)
        else:
            print(f"ğŸ“Š {model_type} iÃ§in CPU ile Faiss L2 indeksi oluÅŸturuluyor")
            index = faiss.IndexFlatL2(d)
        
        # VektÃ¶rleri ekle
        index.add(features)
    
    # Ä°ndeksi Ã¶nbelleÄŸe al
    faiss_indexes[model_type] = index
    
    return index

# Renk benzerliÄŸi hesaplayan fonksiyon
def calculate_color_similarity(color1, color2):
    """Ä°ki RGB rengi arasÄ±ndaki benzerliÄŸi hesaplar (0-1 arasÄ±)"""
    # Euclidean mesafe tabanlÄ± basit benzerlik
    color1 = np.array(color1)
    color2 = np.array(color2)
    
    # 3D renk uzayÄ±nda mesafe hesapla
    distance = np.sqrt(np.sum((color1 - color2)**2))
    
    # Maksimum mesafe 441.67 (255, 255, 255 ile 0, 0, 0 arasÄ±)
    max_distance = np.sqrt(3 * 255**2)
    
    # Mesafeyi benzerliÄŸe dÃ¶nÃ¼ÅŸtÃ¼r (0-1 arasÄ±)
    similarity = 1.0 - (distance / max_distance)
    
    return similarity

# Uyumlu renkleri bulan fonksiyon
def find_harmonious_colors(reference_color, harmony_type="complementary"):
    """Bir referans renge uyumlu renkleri bulan fonksiyon
    
    Args:
        reference_color: RGB formatÄ±nda referans renk [r, g, b]
        harmony_type: Uyum tipi ('complementary', 'analogous', 'triadic', 'split_complementary', 'monochromatic')
    
    Returns:
        Uyumlu renklerin listesi
    """
    # RGB'yi HSV'ye dÃ¶nÃ¼ÅŸtÃ¼r (renk teorisi iÅŸlemleri HSV'de daha kolay)
    hsv_color = colorsys.rgb_to_hsv(reference_color[0]/255, reference_color[1]/255, reference_color[2]/255)
    h, s, v = hsv_color
    
    harmonious_colors = []
    
    if harmony_type == "complementary":
        # TamamlayÄ±cÄ± renk (renk Ã§emberinde 180 derece karÅŸÄ±)
        complementary_h = (h + 0.5) % 1.0
        complementary_rgb = colorsys.hsv_to_rgb(complementary_h, s, v)
        harmonious_colors.append([int(c * 255) for c in complementary_rgb])
    
    elif harmony_type == "analogous":
        # Analog renkler (renk Ã§emberinde +/- 30 derece)
        for angle in [-30, 30]:
            analog_h = (h + angle/360) % 1.0
            analog_rgb = colorsys.hsv_to_rgb(analog_h, s, v)
            harmonious_colors.append([int(c * 255) for c in analog_rgb])
    
    elif harmony_type == "triadic":
        # Triadik renkler (renk Ã§emberinde +/- 120 derece)
        for angle in [120, 240]:
            triad_h = (h + angle/360) % 1.0
            triad_rgb = colorsys.hsv_to_rgb(triad_h, s, v)
            harmonious_colors.append([int(c * 255) for c in triad_rgb])
    
    elif harmony_type == "split_complementary":
        # Split complementary (tamamlayÄ±cÄ± rengin her iki yanÄ±ndan 30'ar derece)
        comp_h = (h + 0.5) % 1.0
        for angle in [-30, 30]:
            split_h = (comp_h + angle/360) % 1.0
            split_rgb = colorsys.hsv_to_rgb(split_h, s, v)
            harmonious_colors.append([int(c * 255) for c in split_rgb])
    
    elif harmony_type == "monochromatic":
        # Monokromatik renkler (aynÄ± rengin farklÄ± ton ve doygunluklarÄ±)
        # Daha aÃ§Ä±k ve daha koyu versiyonlar
        for value_mod in [-0.3, -0.15, 0.15, 0.3]:  # V deÄŸeri deÄŸiÅŸimleri
            new_v = max(0.1, min(0.9, v + value_mod))  # SÄ±nÄ±rlar iÃ§inde tut
            mono_rgb = colorsys.hsv_to_rgb(h, s, new_v)
            harmonious_colors.append([int(c * 255) for c in mono_rgb])
    
    return harmonious_colors

# YardÄ±mcÄ± fonksiyon: Filtre uygulamalarÄ± iÃ§in izin verilen indeksleri oluÅŸtur
def get_allowed_indices(filters, filenames, metadata, model_type, version):
    """Filtre parametrelerine gÃ¶re izin verilen indeksleri dÃ¶ndÃ¼rÃ¼r"""
    allowed_indices = []
    
    if not filters:
        # Filtre yoksa ve versiyon v1 deÄŸilse, versiyon bazlÄ± filtreleme yap
        if version != "v1":
            model_data = get_model_data(model_type)
            version_data = model_data.get("versions", {}).get(version, {})
            version_clusters = version_data.get("clusters", {})
            
            # TÃ¼m clusterlar'daki gÃ¶rselleri topla
            version_images = set()
            for cluster_data in version_clusters.values():
                version_images.update(cluster_data.get("images", []))
            
            # Sadece bu versiyondaki gÃ¶rselleri dahil et
            allowed_indices = [i for i, fname in enumerate(filenames) if fname in version_images]
            print(f"â„¹ï¸ Versiyon filtreleme: {version} versiyonunda {len(allowed_indices)} gÃ¶rsel bulundu.")
        else:
            allowed_indices = list(range(len(filenames)))
        return allowed_indices

    # Filtreleri iÅŸle
    mix_filters = filters.get("mixFilters", [])
    feature_filters = filters.get("features", [])
    cluster_status = filters.get("cluster", "")
    
    # Model verilerini yÃ¼kle (versiyon bilgisi iÃ§in)
    model_data = get_model_data(model_type)

    for i, fname in enumerate(filenames):
        meta = metadata.get(fname, {})
        feature_map = {f[0]: f[1] for f in meta.get("features", [])}
        cluster = meta.get("cluster")

        match_mix = all(
            mix["min"] <= feature_map.get(mix["type"], 0) <= mix["max"]
            for mix in mix_filters
        )

        match_feature = all(f in feature_map for f in feature_filters)

        # Versiyon bazlÄ± cluster kontrolÃ¼
        match_cluster = True
        if cluster_status == "clustered" and not cluster:
            match_cluster = False
        elif cluster_status == "unclustered" and cluster:
            match_cluster = False
            
        # Versiyon kontrolÃ¼: EÄŸer metadata'da cluster bilgisi varsa
        # ve bu cluster belirtilen model ve versiyonda yer alÄ±yorsa, kullan
        if version != "v1" and cluster:  # v1 tÃ¼m gÃ¶rseller iÃ§in varsayÄ±lan
            # Model verisinde bu cluster var mÄ± kontrol et
            version_data = model_data.get("versions", {}).get(version, {})
            version_clusters = version_data.get("clusters", {})
            
            cluster_exists = False
            for cluster_name, cluster_data in version_clusters.items():
                if fname in cluster_data.get("images", []):
                    cluster_exists = True
                    break
            
            # Bu gÃ¶rsel belirtilen versiyonda deÄŸilse ve clustered filtresi varsa, filtreleme yap
            if cluster_status == "clustered" and not cluster_exists:
                match_cluster = False

        if match_mix and match_feature and match_cluster:
            allowed_indices.append(i)
            
    return allowed_indices
setup_training_routes(app)

# Model JSON yÃ¶netimi iÃ§in yardÄ±mcÄ± fonksiyonlar
def get_model_data(model):
    """Model JSON verisini okur"""
    model_path = os.path.join("exported_clusters", model, "versions.json")
    
    if not os.path.exists(model_path):
        # Yeni model dosyasÄ± oluÅŸtur
        data = {
            "current_version": "v1",
            "versions": {}
        }
        # Model klasÃ¶rÃ¼nÃ¼ oluÅŸtur
        os.makedirs(os.path.join("exported_clusters", model), exist_ok=True)
        with open(model_path, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
        return data
        
    try:
        with open(model_path, "r", encoding="utf-8") as f:
            return json.load(f)
    except json.JSONDecodeError:
        # Bozuksa yeniden oluÅŸtur
        return {
            "current_version": "v1",
            "versions": {}
        }

def save_model_data(model, data):
    """Model JSON verisini kaydeder"""
    model_path = os.path.join("exported_clusters", model, "versions.json")
    os.makedirs(os.path.dirname(model_path), exist_ok=True)
    
    with open(model_path, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2, ensure_ascii=False)
    return True

def get_next_version(model):
    """Bir sonraki versiyon adÄ±nÄ± dÃ¶ndÃ¼rÃ¼r (v1, v2, ...)"""
    data = get_model_data(model)
    versions = data["versions"].keys()
    
    if not versions:
        return "v1"
        
    # v1, v2, ... formatÄ±ndaki versiyonlarÄ± bul
    v_numbers = [int(v[1:]) for v in versions if v.startswith("v") and v[1:].isdigit()]
    
    if not v_numbers:
        return "v1"
        
    return f"v{max(v_numbers) + 1}"

# Metadata gÃ¼ncelleme yardÄ±mcÄ± fonksiyonu
def update_metadata(filename, updates):
    """GÃ¶rsel metadatasÄ±nÄ± gÃ¼nceller"""
    metadata_path = "image_metadata_map.json"
    try:
        with open(metadata_path, "r", encoding="utf-8") as f:
            metadata = json.load(f)
        
        if filename in metadata:
            metadata[filename].update(updates)
        else:
            metadata[filename] = updates
            
        with open(metadata_path, "w", encoding="utf-8") as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
            
        return True
    except Exception as e:
        print(f"Metadata gÃ¼ncelleme hatasÄ±: {str(e)}")
        return False

@app.route("/")
def home():
    return "<h2>PU Ana Panel </h2><p>/train ile model eÄŸit, /check-updates ile gÃ¼ncelle kontrol et.</p>"


@app.route("/train")
def train():
    return render_template("train.html")

@app.route("/pu")
def pu_screen():
    return render_template("pu.html")

@app.route("/train-model", methods=["POST"])
def train_model_route():
    data = request.get_json()
    with open("train_config.json", "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2)

    # EÄŸitim klasÃ¶rÃ¼ yoksa oluÅŸtur
    cluster_path = os.path.join("exported_clusters", data["model_type"])
    os.makedirs(cluster_path, exist_ok=True)

    python_exe = sys.executable
    env = os.environ.copy()
    env["PYTHONIOENCODING"] = "utf-8"

    try:
        result = subprocess.run([python_exe, "train_model.py"], capture_output=True, text=True, check=True, env=env)
        print(result.stdout)

        # EÄŸitim sonrasÄ± Ã¶zet satÄ±rÄ± bul (âœ… EÄŸitim Ã–zeti: ...)
        summary_line = ""
        for line in result.stdout.splitlines():
            if line.startswith("âœ… EÄŸitim Ã–zeti"):
                summary_line = line
                break

        status_msg = summary_line if summary_line else "âœ… EÄŸitim baÅŸarÄ±yla tamamlandÄ±."
        return jsonify({"status": status_msg})
    except subprocess.CalledProcessError as e:
        return jsonify({"status": f"âŒ EÄŸitim sÄ±rasÄ±nda hata: {e.stderr}"})

@app.route('/image_metadata_map.json')
def serve_metadata_map():
    return send_from_directory('.', 'image_metadata_map.json')

@app.route('/realImages/<path:filename>')
def serve_real_image(filename):
    return send_from_directory('realImages', filename)

@app.route("/check-updates")
def check_updates():
    try:
        from check_updates import check_for_updates
        changes = check_for_updates()
        
        if changes.get("has_changes", False):
            print(f"ğŸ” DeÄŸiÅŸiklik algÄ±landÄ±: {changes.get('summary', {})}")
            return jsonify({
                "status": "changes_detected",
                "changes": changes,
                "message": changes.get("notification", {}).get("message", "DeÄŸiÅŸiklikler algÄ±landÄ±.")
            })
        else:
            return jsonify({
                "status": "up_to_date",
                "message": changes.get("message", "âœ… DeÄŸiÅŸiklik yok, metadata gÃ¼ncel.")
            })
    except Exception as ex:
        traceback.print_exc()
        return jsonify({
            "status": "error",
            "message": f"âŒ Hata oluÅŸtu: {str(ex)}"
        })
@app.route('/thumbnails/<path:filename>')
def serve_thumbnail(filename):
    return send_from_directory('thumbnails', filename)

@app.route("/clusters/<model>/<version>/data")
def serve_cluster_data(model, version):
    """Model versiyon bilgilerini dÃ¶ndÃ¼rÃ¼r"""
    model_data = get_model_data(model)
    
    # EÄŸer versiyon yoksa hata dÃ¶ndÃ¼r
    if version not in model_data.get("versions", {}):
        return jsonify({"error": "Versiyon bulunamadÄ±"}), 404
    
    # Versiyon iÃ§eriklerini kontrol et
    version_data = model_data["versions"][version]
    clusters = version_data.get("clusters", {})
    cluster_count = len(clusters)
    total_images = 0
    
    # Her cluster'daki gÃ¶rsel sayÄ±sÄ±nÄ± topla
    for cluster_name, cluster_data in clusters.items():
        total_images += len(cluster_data.get("images", []))
    
    print(f"\n[DEBUG] Model: {model}, Version: {version}")
    print(f"[DEBUG] Cluster count: {cluster_count}")
    print(f"[DEBUG] Total images: {total_images}")
    print(f"[DEBUG] Clusters: {list(clusters.keys())}\n")
    
    # Sadece istenen versiyonun verisini dÃ¶ndÃ¼r
    return jsonify({
        "version": version,
        "data": model_data["versions"][version],
        "stats": {
            "cluster_count": cluster_count,
            "total_images": total_images
        }
    })

@app.route("/find-similar", methods=["GET", "POST"])
def find_similar():
    global cached_metadata
    
    start_time = datetime.now()  # Performans Ã¶lÃ§Ã¼mÃ¼ iÃ§in baÅŸlangÄ±Ã§ zamanÄ±
    
    filters = request.get_json() if request.method == "POST" else None
    filename = request.args.get("filename")
    model = request.args.get("model", "pattern")
    version = request.args.get("version", "v1")
    topN = int(request.args.get("topN", 100))
    metric = request.args.get("metric", "cosine")
    
    print(f"ğŸ“Š Benzer gÃ¶rsel arama: model={model}, version={version}, metric={metric}")

    # Gerekli dosya yollarÄ±
    feature_path = f"image_features/{model}_features.npy"
    index_path = f"image_features/{model}_filenames.json"
    metadata_path = "image_metadata_map.json"

    if not os.path.exists(feature_path) or not os.path.exists(index_path):
        return jsonify([])

    # Ã–nbellekte yoksa dosya isimlerini yÃ¼kle
    if model not in cached_filenames:
        with open(index_path, "r", encoding="utf-8") as f:
            cached_filenames[model] = json.load(f)
    filenames = cached_filenames[model]
    
    # Ã–nbellekte yoksa metadata yÃ¼kle
    if cached_metadata is None:
        with open(metadata_path, "r", encoding="utf-8") as f:
            cached_metadata = json.load(f)
    metadata = cached_metadata

    if filename not in filenames:
        return jsonify([])

    # Faiss indeksini al veya oluÅŸtur
    index = get_faiss_index(model)
    if index is None:
        return jsonify([])
    
    # VektÃ¶r indeksini bul
    idx = filenames.index(filename)
    
    # Sorgu vektÃ¶rÃ¼nÃ¼ al
    features = cached_features[model]
    query_vector = features[idx].reshape(1, -1).copy().astype(np.float32)
    
    # KosinÃ¼s benzerliÄŸi iÃ§in L2 normalizasyon
    if model in ["pattern", "color+pattern"] or metric == "cosine":
        faiss.normalize_L2(query_vector)
    
    # Filtreleri uygula
    allowed_indices = get_allowed_indices(filters, filenames, metadata, model, version)
    
    if not allowed_indices:
        return jsonify([])
    
    # Ã–zel durum: AranÄ±lan gÃ¶rseli sonuÃ§lara ekleyelim
    # ve benzerlik skorunu 1.0 olarak ayarlayalÄ±m (tam eÅŸleÅŸme)
    query_idx = filenames.index(filename)
    is_query_in_allowed = query_idx in allowed_indices
    
    # FiltrelenmiÅŸ indeksler iÃ§in geÃ§ici arama
    k = min(topN, len(allowed_indices))
    
    # FiltrelenmiÅŸ vektÃ¶rleri al
    filtered_features = features[allowed_indices].copy().astype(np.float32)
    
    # GeÃ§ici indeks oluÅŸtur ve arama yap
    if model in ["pattern", "color+pattern"] or metric == "cosine":
        # KosinÃ¼s benzerliÄŸi iÃ§in IP indeksi kullan
        # Normalize edilmiÅŸ vektÃ¶rler arasÄ±ndaki iÃ§ Ã§arpÄ±m
        # doÄŸrudan kosinÃ¼s benzerliÄŸini verir (1.0 = tam benzerlik)
        faiss.normalize_L2(filtered_features)
        temp_index = faiss.IndexFlatIP(filtered_features.shape[1])
        temp_index.add(filtered_features)
        distances, indices = temp_index.search(query_vector, k)
        
        # IP indeksi zaten kosinÃ¼s benzerliÄŸi verir, normalize edilmiÅŸ vektÃ¶rler iÃ§in.
        # Faiss, benzerliÄŸi azalmayan sÄ±rada dÃ¶ndÃ¼rÃ¼r (-1 ile 1 arasÄ±nda)
        # DÃ¶nÃ¼ÅŸtÃ¼rerek [0,1] aralÄ±ÄŸÄ±na getiriyoruz
        # (1.0 = tam benzerlik, 0.0 = iliÅŸkisiz)
        similarity_transform = lambda d: float(max(0, d))  # Negatif deÄŸerleri sÄ±fÄ±rla
    else:
        # L2 mesafesi iÃ§in
        temp_index = faiss.IndexFlatL2(filtered_features.shape[1])
        temp_index.add(filtered_features)
        distances, indices = temp_index.search(query_vector, k)
        
        # L2 mesafesi iÃ§in benzerlik dÃ¶nÃ¼ÅŸÃ¼mÃ¼ (0 = tam benzerlik)
        similarity_transform = lambda d: float(1.0 / (1.0 + d))
    
    # SonuÃ§larÄ± hazÄ±rla
    final_results = []
    
    # Ã–nce, arama yapÄ±lan gÃ¶rseli en baÅŸa ekle (tam eÅŸleÅŸme)
    if is_query_in_allowed:
        query_meta = metadata.get(filename, {})
        
        # Versiyon spesifik cluster bilgisi
        query_cluster_info = query_meta.get("cluster", "")
        if version != "v1" and query_cluster_info:
            model_data = get_model_data(model)
            version_data = model_data.get("versions", {}).get(version, {})
            version_clusters = version_data.get("clusters", {})
            
            # Bu gÃ¶rselin bu versiyondaki cluster'Ä±nÄ± bul
            for cluster_name, cluster_data in version_clusters.items():
                if filename in cluster_data.get("images", []):
                    query_cluster_info = cluster_name
                    break
        
        final_results.append({
            "filename": filename,
            "design": query_meta.get("design"),
            "season": query_meta.get("season"),
            "quality": query_meta.get("quality"),
            "features": query_meta.get("features", []),
            "cluster": query_cluster_info,
            "version": version,
            "similarity": 1.0  # Tam eÅŸleÅŸme her zaman 1.0
        })
    
    # Sonra diÄŸer benzer gÃ¶rselleri ekle
    for i, idx in enumerate(indices[0]):
        if idx >= len(allowed_indices):
            continue
            
        global_idx = allowed_indices[idx]
        fname = filenames[global_idx]
        
        # EÄŸer bu gÃ¶rsel arama yapÄ±lan gÃ¶rselin kendisiyse, atla (zaten ekledik)
        if fname == filename:
            continue
            
        meta = metadata.get(fname, {})
        
        # Benzerlik skoru hesapla
        similarity = similarity_transform(distances[0][i])
        
        # Versiyon spesifik cluster bilgisi
        cluster_info = meta.get("cluster", "")
        if version != "v1" and cluster_info:
            model_data = get_model_data(model)
            version_data = model_data.get("versions", {}).get(version, {})
            version_clusters = version_data.get("clusters", {})
            
            # Bu gÃ¶rselin bu versiyondaki cluster'Ä±nÄ± bul
            for cluster_name, cluster_data in version_clusters.items():
                if fname in cluster_data.get("images", []):
                    cluster_info = cluster_name
                    break
        
        final_results.append({
            "filename": fname,
            "design": meta.get("design"),
            "season": meta.get("season"),
            "quality": meta.get("quality"),
            "features": meta.get("features", []),
            "cluster": cluster_info,
            "version": version,
            "similarity": similarity
        })
    
    # Performans Ã¶lÃ§Ã¼mÃ¼
    end_time = datetime.now()
    duration_ms = (end_time - start_time).total_seconds() * 1000
    print(f"â±ï¸ Benzerlik aramasÄ± {duration_ms:.1f} ms'de tamamlandÄ±")
    
    return jsonify(final_results)


@app.route("/update-version-comment", methods=["POST"])
def update_version_comment():
    data = request.get_json()
    model = data.get("model")
    version = data.get("version")
    comment = data.get("version_comment", "")

    if not model or not version:
        return jsonify({"status": "error", "message": "Model ve versiyon belirtilmelidir."})

    try:
        model_data = get_model_data(model)
        
        if version not in model_data.get("versions", {}):
            return jsonify({"status": "error", "message": "Belirtilen versiyon bulunamadÄ±."})
        
        model_data["versions"][version]["comment"] = comment
        save_model_data(model, model_data)

        return jsonify({"status": "ok"})
    except Exception as e:
        return jsonify({"status": "error", "message": str(e)})


@app.route("/create-cluster", methods=["POST"])
def create_cluster():
    data = request.get_json()
    model = data.get("model")
    version = data.get("version")
    filenames = data.get("filenames", [])

    if not model or not version or not filenames:
        return jsonify({"status": "error", "message": "Model, versiyon ve gÃ¶rsel listesi gerekli."})

    try:
        # Model verisini al
        model_data = get_model_data(model)
        
        # Versiyon kontrolÃ¼
        if version not in model_data["versions"]:
            model_data["versions"][version] = {
                "created_at": datetime.now().isoformat(),
                "comment": f"{model} modeli {version} versiyonu",
                "algorithm": "manual",
                "parameters": {},
                "clusters": {}
            }
        
        # Eski cluster'lardan seÃ§ili gÃ¶rselleri Ã§Ä±kar
        version_data = model_data["versions"][version]
        for cluster_name, cluster_data in list(version_data["clusters"].items()):
            cluster_data["images"] = [img for img in cluster_data["images"] if img not in filenames]
            
            # EÄŸer cluster boÅŸalmÄ±ÅŸsa ve temsil eden gÃ¶rsel de Ã§Ä±karÄ±ldÄ±ysa, cluster'Ä± sil
            if not cluster_data["images"] or cluster_data["representative"] in filenames:
                if cluster_data["images"]:
                    # BoÅŸ deÄŸilse ama temsil eden gÃ¶rsel Ã§Ä±karÄ±ldÄ±ysa, yeni temsil eden gÃ¶rsel seÃ§
                    cluster_data["representative"] = cluster_data["images"][0]
                else:
                    # Tamamen boÅŸsa cluster'Ä± sil
                    del version_data["clusters"][cluster_name]
        
        # Yeni cluster adÄ±
        existing_clusters = list(version_data["clusters"].keys())
        cluster_numbers = [int(c.split("-")[-1]) for c in existing_clusters if c.startswith("cluster-") and c.split("-")[-1].isdigit()]
        next_id = max(cluster_numbers + [0]) + 1
        new_cluster_name = f"cluster-{next_id}"
        
        # Thumbnail klasÃ¶rÃ¼nÃ¼ oluÅŸtur (eÄŸer yoksa)
        thumbnail_path = os.path.join("exported_clusters", model, version, "thumbnails")
        os.makedirs(thumbnail_path, exist_ok=True)
        
        # GÃ¶rsellerin thumbnail'larÄ±nÄ± kopyala
        for fname in filenames:
            src_thumb = os.path.join("thumbnails", fname)
            dst_thumb = os.path.join(thumbnail_path, fname)
            
            if os.path.exists(src_thumb):
                shutil.copy2(src_thumb, dst_thumb)
                
            # Metadatada gÃ¼ncelle
            update_metadata(fname, {"cluster": new_cluster_name})
        
        # Yeni cluster'a gÃ¶rselleri ekle
        version_data["clusters"][new_cluster_name] = {
            "representative": filenames[0],
            "images": filenames,
            "comment": ""
        }
        
        # Model verisini kaydet
        save_model_data(model, model_data)

        return jsonify({"status": "ok", "new_cluster": new_cluster_name})

    except Exception as e:
        import traceback
        print(f"Cluster oluÅŸturma hatasÄ±: {str(e)}")
        print(traceback.format_exc())
        return jsonify({"status": "error", "message": str(e)})

# --- YENÄ°: Feedback kaydÄ± alma endpointi ---
@app.route("/submit-feedback", methods=["POST"])
def submit_feedback():
    feedback = request.get_json()
    print("ğŸ“© Feedback alÄ±ndÄ±:", feedback)

    feedback_file = "feedback_log.json"
    feedback_list = []

    if os.path.exists(feedback_file):
        with open(feedback_file, "r", encoding="utf-8") as f:
            try:
                feedback_list = json.load(f)
            except json.JSONDecodeError:
                feedback_list = []

    # AynÄ± anchor-output-model-version varsa gÃ¼ncelle / iptal et
    anchor = feedback.get("anchor")
    output = feedback.get("output")
    model = feedback.get("model")
    version = feedback.get("version")

    feedback_list = [f for f in feedback_list if not (
        f.get("anchor") == anchor and
        f.get("output") == output and
        f.get("model") == model and
        f.get("version") == version
    )]

    if feedback.get("feedback") is not None:
        feedback_list.append(feedback)

    with open(feedback_file, "w", encoding="utf-8") as f:
        json.dump(feedback_list, f, indent=2, ensure_ascii=False)

    return jsonify({"status": "ok"})

@app.route("/init-model-version", methods=["POST"])
def init_model_version():
    """Yeni bir model ve versiyon kombinasyonu iÃ§in gereken baÅŸlangÄ±Ã§ yapÄ±sÄ±nÄ± oluÅŸturur"""
    data = request.get_json()
    model = data.get("model")
    version = data.get("version")
    
    if not model or not version:
        return jsonify({"status": "error", "message": "Model ve versiyon belirtilmeli."})
    
    # Model ve versiyon klasÃ¶rlerini oluÅŸtur
    version_path = os.path.join("exported_clusters", model, version)
    os.makedirs(version_path, exist_ok=True)
    
    # BoÅŸ representatives.json dosyasÄ± oluÅŸtur
    rep_data = {
        "representatives": [],
        "clusters": [],
        "version_comment": f"{model} modeli {version} versiyonu",
        "last_updated": datetime.now().isoformat()
    }
    
    rep_path = os.path.join(version_path, "representatives.json")
    with open(rep_path, "w", encoding="utf-8") as f:
        json.dump(rep_data, f, indent=2, ensure_ascii=False)
    
    return jsonify({"status": "ok", "message": f"{model} modeli {version} versiyonu hazÄ±rlandÄ±."})

@app.route("/move-to-cluster", methods=["POST"])
def move_to_cluster():
    data = request.get_json()
    model = data.get("model", "pattern") 
    version = data.get("version", "v1")   
    cluster_name = data.get("cluster")
    images = data.get("images", [])

    if not cluster_name or not images:
        return jsonify({"status": "error", "message": "Eksik bilgi"}), 400

    try:
        # Model verisini al
        model_data = get_model_data(model)
        
        # Versiyon kontrolÃ¼
        if version not in model_data["versions"]:
            return jsonify({"status": "error", "message": "Versiyon bulunamadÄ±"}), 404
            
        version_data = model_data["versions"][version]
        
        # Cluster kontrolÃ¼
        if cluster_name not in version_data["clusters"]:
            return jsonify({"status": "error", "message": "Cluster bulunamadÄ±"}), 404
        
        # Metadata dosyasÄ±nÄ± yÃ¼kle
        metadata_path = "image_metadata_map.json"
        with open(metadata_path, "r", encoding="utf-8") as f:
            metadata = json.load(f)

        moved = []
        
        # GÃ¶rselleri diÄŸer clusterlardan Ã§Ä±kar
        for existing_cluster, cluster_data in list(version_data["clusters"].items()):
            if existing_cluster == cluster_name:
                continue
                
            # GÃ¶rselleri filtrele
            cluster_data["images"] = [img for img in cluster_data["images"] if img not in images]
            
            # Temsil eden gÃ¶rsel taÅŸÄ±ndÄ±ysa, yeni temsil eden seÃ§
            if cluster_data["representative"] in images and cluster_data["images"]:
                cluster_data["representative"] = cluster_data["images"][0]
            
            # EÄŸer cluster boÅŸalmÄ±ÅŸsa ve temsil eden gÃ¶rsel de taÅŸÄ±ndÄ±ysa, cluster'Ä± sil
            if not cluster_data["images"]:
                del version_data["clusters"][existing_cluster]
        
        # GÃ¶rselleri thumbnail olarak kopyala
        thumbnail_path = os.path.join("exported_clusters", model, version, "thumbnails")
        os.makedirs(thumbnail_path, exist_ok=True)
        
        for img in images:
            src_thumb = os.path.join("thumbnails", img)
            dst_thumb = os.path.join(thumbnail_path, img)
            
            if os.path.exists(src_thumb):
                shutil.copy2(src_thumb, dst_thumb)
                moved.append(img)
            else:
                print(f"âš ï¸ Thumbnail bulunamadÄ±: {img}")
            
            # Hedef cluster'a ekle
            if img not in version_data["clusters"][cluster_name]["images"]:
                version_data["clusters"][cluster_name]["images"].append(img)

            # Metadata'da cluster gÃ¼ncelle
            if img in metadata:
                metadata[img]["cluster"] = cluster_name
            else:
                print(f"ğŸ“› Metadata'da {img} bulunamadÄ±")

        # Metadata'yÄ± kaydet
        with open(metadata_path, "w", encoding="utf-8") as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
            
        # Model verisini kaydet
        save_model_data(model, model_data)

        return jsonify({"status": "ok", "moved": moved, "cluster": cluster_name})
        
    except Exception as e:
        import traceback
        print(f"GÃ¶rsel taÅŸÄ±ma hatasÄ±: {str(e)}")
        print(traceback.format_exc())
        return jsonify({"status": "error", "message": str(e)}), 500

@app.route("/create-new-version", methods=["POST"])
def create_new_version():
    """Yeni bir model versiyonu oluÅŸturur ve clustering yapar"""
    data = request.get_json()
    
    model = data.get("model", "pattern")
    algorithm = data.get("algorithm", "kmeans")
    parameters = data.get("parameters", {})
    comment = data.get("comment", "")
    
    # Yeni versiyon adÄ±nÄ± belirle
    new_version = get_next_version(model)
    
    # Model datasÄ±nÄ± al
    model_data = get_model_data(model)
    
    # Cluster config oluÅŸtur
    cluster_config = {
        "model_type": model,
        "version": new_version,
        "algorithm": algorithm,
        **parameters
    }
    
    # Config'i kaydet
    with open("cluster_config.json", "w", encoding="utf-8") as f:
        json.dump(cluster_config, f, indent=2, ensure_ascii=False)
    
    try:
        # Versiyon klasÃ¶rÃ¼nÃ¼ oluÅŸtur
        version_path = os.path.join("exported_clusters", model, new_version)
        thumbnail_path = os.path.join(version_path, "thumbnails")
        os.makedirs(thumbnail_path, exist_ok=True)
        
        # Auto cluster'Ä± Ã§alÄ±ÅŸtÄ±r
        python_exe = sys.executable
        env = os.environ.copy()
        env["PYTHONIOENCODING"] = "utf-8"
        
        result = subprocess.run(
            [python_exe, "auto_cluster.py"], 
            capture_output=True, 
            text=True, 
            check=True, 
            env=env
        )
        
        # Ã‡Ä±ktÄ±dan cluster bilgilerini al
        cluster_count = 0
        for line in result.stdout.splitlines():
            if "kÃ¼me oluÅŸturuldu" in line:
                parts = line.split()
                try:
                    cluster_count = int(parts[parts.index("kÃ¼me") - 1])
                except (ValueError, IndexError):
                    pass
        
        # GÃ¼ncel verileri al
        updated_model_data = get_model_data(model)
        updated_version_data = updated_model_data["versions"].get(new_version, {})
        actual_clusters = updated_version_data.get("clusters", {})
        actual_cluster_count = len(actual_clusters)
        
        return jsonify({
            "status": "ok", 
            "version": new_version,
            "cluster_count": actual_cluster_count or cluster_count,
            "message": f"{model} modeli iÃ§in {new_version} versiyonu oluÅŸturuldu."
        })
    
    except Exception as e:
        return jsonify({"status": "error", "message": str(e)})

@app.route("/available-versions")
def available_versions():
    """Bir model iÃ§in mevcut tÃ¼m versiyonlarÄ± listeler"""
    model = request.args.get("model", "pattern")
    
    try:
        model_data = get_model_data(model)
        versions = []
        
        for version_id in model_data["versions"].keys():
            version_data = model_data["versions"][version_id]
            version_name = f"Versiyon {version_id[1:]}" if version_id.startswith("v") else version_id
            
            # Ä°steÄŸe baÄŸlÄ± olarak versiyon hakkÄ±nda daha fazla bilgi eklenebilir
            versions.append({
                "id": version_id,
                "name": version_name,
                "algorithm": version_data.get("algorithm", "unknown"),
                "created_at": version_data.get("created_at", ""),
                "comment": version_data.get("comment", "")
            })
        
        # EÄŸer liste boÅŸsa varsayÄ±lan ekle
        if not versions:
            versions.append({"id": "v1", "name": "Versiyon 1"})
            
        return jsonify(versions)
    except Exception as e:
        print(f"Versiyon listesi alÄ±nÄ±rken hata: {str(e)}")
        return jsonify([{"id": "v1", "name": "Versiyon 1"}])

# Yeni: DeÄŸiÅŸiklikleri uygulama endpoint'i
@app.route("/apply-updates", methods=["POST"])
def apply_updates():
    try:
        from check_updates import apply_updates, check_for_updates
        
        # Ä°lk Ã¶nce deÄŸiÅŸiklikleri kontrol et
        changes = check_for_updates()
        
        if not changes.get("has_changes", False):
            return jsonify({
                "status": "no_changes", 
                "message": "Uygulanacak deÄŸiÅŸiklik bulunamadÄ±."
            })
        
        # Ä°ÅŸlem zaten devam ediyorsa bildir
        if os.path.exists('updating_clusters.flag'):
            flag_age = time.time() - os.path.getmtime('updating_clusters.flag')
            return jsonify({
                "status": "in_progress",
                "message": f"â³ BaÅŸka bir gÃ¼ncelleme iÅŸlemi {flag_age/60:.1f} dakikadÄ±r devam ediyor, lÃ¼tfen bekleyin."
            })
            
        # DeÄŸiÅŸiklikleri uygula
        results = apply_updates(changes)
        
        # Faiss indekslerini temizle
        global faiss_indexes, cached_features, cached_filenames, cached_metadata
        faiss_indexes = {}
        cached_features = {}
        cached_filenames = {}
        cached_metadata = None
        
        return jsonify({
            "status": results.get("status", "success"),
            "message": "âœ… DeÄŸiÅŸiklikler baÅŸarÄ±yla uygulandÄ±" if results.get("status") == "success" else "âš ï¸ BazÄ± deÄŸiÅŸiklikler uygulanamadÄ±",
            "results": results
        })
    except Exception as ex:
        traceback.print_exc()
        return jsonify({
            "status": "error",
            "message": f"âŒ Hata oluÅŸtu: {str(ex)}"
        })

# Yeni: DeÄŸiÅŸiklikleri yoksay endpoint'i
@app.route("/ignore-updates", methods=["POST"])
def ignore_updates():
    try:
        data = request.get_json()
        previous_cache = data.get("previous_cache", {})
        
        # Ã–nceki cache durumunu kaydet (deÄŸiÅŸiklikleri yoksaymak iÃ§in)
        if previous_cache:
            from check_updates import save_current_cache
            save_current_cache(
                previous_cache.get("images", []), 
                previous_cache.get("json_hashes", {})
            )
            return jsonify({"status": "ok", "message": "DeÄŸiÅŸiklikler yoksayÄ±ldÄ±."})
        else:
            return jsonify({"status": "error", "message": "Ã–nceki cache bilgisi bulunamadÄ±."})
    except Exception as ex:
        traceback.print_exc()
        return jsonify({"status": "error", "message": f"âŒ Hata oluÅŸtu: {str(ex)}"})

# Yeni: Sistem bilgilerini dÃ¶ndÃ¼r
@app.route("/system-info")
def system_info():
    # Faiss GPU desteÄŸi kontrolÃ¼
    gpu_count = faiss.get_num_gpus()
    uses_gpu = gpu_count > 0
    
    # Mevcut model tipleri ve versiyonlarÄ±
    models = []
    for model_type in ["pattern", "color", "texture", "color+pattern"]:
        model_path = os.path.join("exported_clusters", model_type, "versions.json")
        if os.path.exists(model_path):
            try:
                with open(model_path, "r", encoding="utf-8") as f:
                    model_data = json.load(f)
                
                model_info = {
                    "model_type": model_type,
                    "current_version": model_data.get("current_version", "v1"),
                    "versions": list(model_data.get("versions", {}).keys())
                }
                models.append(model_info)
            except:
                pass
    
    # Model Ã¶zellikleri
    features_info = []
    for model_type in ["pattern", "color", "texture", "color+pattern"]:
        feature_path = f"image_features/{model_type}_features.npy"
        if os.path.exists(feature_path):
            try:
                features = np.load(feature_path)
                features_info.append({
                    "model_type": model_type,
                    "shape": list(features.shape),
                    "size_mb": round(os.path.getsize(feature_path) / (1024 * 1024), 2)
                })
            except:
                pass
    
    # GÃ¶rsel sayÄ±sÄ±
    image_count = len([f for f in os.listdir("realImages") if f.lower().endswith(('.jpg', '.jpeg', '.png'))])
    
    return jsonify({
        "app_version": APP_VERSION,
        "last_updated": APP_LAST_UPDATED,
        "faiss": {
            "gpu_count": gpu_count,
            "uses_gpu": uses_gpu
        },
        "models": models,
        "features": features_info,
        "image_count": image_count,
        "environment": {
            "python_version": sys.version.split()[0]
        }
    })

# Yeni: Uyumlu renklere sahip kumaÅŸlarÄ± bulma endpoint'i
@app.route("/find-harmonious")
def find_harmonious():
    fabric_id = request.args.get("fabricId")
    harmony_type = request.args.get("harmonyType", "complementary")
    threshold = float(request.args.get("threshold", "80")) / 100  # YÃ¼zdeyi ondalikli sayÄ±ya Ã§evir
    result_count = int(request.args.get("resultCount", "20"))
    current_season_only = request.args.get("currentSeasonOnly", "false").lower() == "true"
    current_quality_only = request.args.get("currentQualityOnly", "false").lower() == "true"
    
    # Parametreleri kontrol et
    if not fabric_id:
        return jsonify({"status": "error", "message": "fabricId parametresi gerekli."})
        
    if harmony_type not in ["complementary", "analogous", "triadic", "split_complementary", "monochromatic"]:
        harmony_type = "complementary"  # VarsayÄ±lan olarak tamamlayÄ±cÄ± renk kullan
    
    # SeÃ§ilen kumaÅŸÄ±n dosya yolu
    img_path = os.path.join("realImages", fabric_id)
    if not os.path.exists(img_path):
        return jsonify({"status": "error", "message": f"GÃ¶rsel dosyasÄ± bulunamadÄ±: {fabric_id}"})
    
    # Metadata dosyasÄ±nÄ± kontrol et
    if not os.path.exists("image_metadata_map.json"):
        return jsonify({"status": "error", "message": "Metadata dosyasÄ± bulunamadÄ±."})
    
    # Metadata yÃ¼kle
    with open("image_metadata_map.json", "r", encoding="utf-8") as f:
        metadata = json.load(f)
    
    # KumaÅŸÄ±n 1x1 indirgenerek dominant renk bilgisini al
    img = cv2.imread(img_path)
    if img is None:
        return jsonify({"status": "error", "message": "GÃ¶rsel dosyasÄ± okunamadÄ±."})
    
    # RGB dominant rengi al (BGR'den RGB'ye dÃ¶nÃ¼ÅŸtÃ¼r)
    dominant_color = cv2.resize(img, (1, 1))[0, 0].tolist()  # [B, G, R] formatÄ±nda
    dominant_color = dominant_color[::-1]  # [R, G, B] formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼r
    
    # Uyumlu renkleri bul
    harmonious_colors = find_harmonious_colors(dominant_color, harmony_type)
    
    # Referans kumaÅŸÄ±n metadata bilgisini al (filtreleme iÃ§in)
    reference_metadata = metadata.get(fabric_id, {})
    reference_season = reference_metadata.get("season")
    reference_quality = reference_metadata.get("quality")
    
    # DÃ¶ndÃ¼rÃ¼lecek sonuÃ§larÄ± hazÄ±rla
    results = []
    found_count = 0
    
    # TÃ¼m realImages klasÃ¶rÃ¼ndeki kumaÅŸlarÄ± tara
    all_fabrics = [f for f in os.listdir("realImages") if f.lower().endswith(('.jpg', '.jpeg', '.png'))]
    
    for fabric_name in all_fabrics:
        if fabric_name == fabric_id:
            continue  # Kendisini dÄ±ÅŸarÄ±da bÄ±rak
        
        # Bu kumaÅŸÄ±n metadata bilgisini al (eÄŸer varsa)
        fabric_metadata = metadata.get(fabric_name, {})
        
        # Filtreleme seÃ§enekleri kontrol
        if current_season_only and reference_season and fabric_metadata.get("season") != reference_season:
            continue  # Mevsim eÅŸleÅŸmezse atla
            
        if current_quality_only and reference_quality and fabric_metadata.get("quality") != reference_quality:
            continue  # Kalite eÅŸleÅŸmezse atla
        
        fabric_img_path = os.path.join("realImages", fabric_name)
        fabric_img = cv2.imread(fabric_img_path)
        if fabric_img is None:
            continue
        
        # KumaÅŸÄ±n dominant rengini al (BGR'den RGB'ye dÃ¶nÃ¼ÅŸtÃ¼r)
        fabric_dominant_color = cv2.resize(fabric_img, (1, 1))[0, 0].tolist()[::-1]  # [R, G, B]
        
        # Bu kumaÅŸÄ±n rengi, uyumlu renklerden herhangi birine ne kadar benzer?
        best_similarity = 0
        best_harmony_color = None
        
        for harmonious_color in harmonious_colors:
            similarity = calculate_color_similarity(harmonious_color, fabric_dominant_color)
            if similarity > best_similarity:
                best_similarity = similarity
                best_harmony_color = harmonious_color
        
        # Benzerlik belirli bir eÅŸiÄŸin Ã¼zerindeyse, sonuÃ§lara ekle
        if best_similarity > threshold:
            results.append({
                "filename": fabric_name,
                "similarity": round(float(best_similarity), 3),
                "harmony_type": harmony_type,
                "harmony_color": best_harmony_color,
                "dominant_color": fabric_dominant_color,
                "design": fabric_metadata.get("design"),
                "season": fabric_metadata.get("season"),
                "features": fabric_metadata.get("features", []),
                "quality": fabric_metadata.get("quality")
            })
            found_count += 1
            
            # SonuÃ§ sayÄ±sÄ± limiti aÅŸÄ±ldÄ±ysa dÃ¶ngÃ¼yÃ¼ sonlandÄ±r
            if found_count >= result_count:
                break
    
    # BenzerliÄŸe gÃ¶re sÄ±rala (en benzerden baÅŸlayarak)
    results = sorted(results, key=lambda x: x["similarity"], reverse=True)
    
    # SonuÃ§larÄ± dÃ¶ndÃ¼r
    return jsonify({
        "status": "success",
        "reference_fabric": fabric_id,
        "reference_color": dominant_color,
        "harmony_type": harmony_type,
        "harmony_colors": harmonious_colors,
        "found_count": found_count,
        "results": results
    })

# Yeni: Faiss indekslerini sÄ±fÄ±rlama endpoint'i
@app.route("/reset-faiss-indexes")
def reset_faiss_indexes():
    global faiss_indexes, cached_features, cached_filenames, cached_metadata
    faiss_indexes = {}
    cached_features = {}
    cached_filenames = {}
    cached_metadata = None
    return jsonify({"status": "ok", "message": "Faiss indeksleri sÄ±fÄ±rlandÄ±."})

# app.py baÅŸlatÄ±lÄ±rken Faiss indekslerinin durumunu kontrol et
def check_faiss_reset_flag():
    flag_file = "reset_faiss_indexes.flag"
    if os.path.exists(flag_file):
        # DosyayÄ± sil
        os.remove(flag_file)
        # Faiss indekslerini sÄ±fÄ±rla
        global faiss_indexes, cached_features, cached_filenames, cached_metadata
        faiss_indexes = {}
        cached_features = {}
        cached_filenames = {}
        cached_metadata = None
        print("ğŸ”„ Faiss indeksleri sÄ±fÄ±rlandÄ± (reset flag algÄ±landÄ±)")

# UygulamayÄ± baÅŸlatÄ±rken flag kontrolÃ¼
check_faiss_reset_flag()

if __name__ == "__main__":
    # Uygulama baÅŸlarken bir temizlik zamanlamasÄ± baÅŸlat
    clean_timer = threading.Timer(4 * 60 * 60, clean_faiss_indexes_periodically)  # 4 saat
    clean_timer.daemon = True
    clean_timer.start()
    
    app.run(debug=True, use_reloader=False)
