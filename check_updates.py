# check_updates.py
# Bu dosya, realImages klasÃ¶rÃ¼ndeki gÃ¶rseller ve realImages_json iÃ§indeki JSON dosyalarÄ±nda bir deÄŸiÅŸiklik olup olmadÄ±ÄŸÄ±nÄ± kontrol eder.
# Yeni gÃ¶rseller veya gÃ¼ncellenmiÅŸ JSON tespit edilirse, merge_metadata.py, generate_thumbnails.py ve generate_representatives.py Ã§alÄ±ÅŸtÄ±rÄ±lÄ±r.
# OluÅŸturulma: 2025-04-19
# HazÄ±rlayan: Kafkas

import os
import time
import json
import hashlib
import subprocess
from merge_metadata import load_json

REAL_IMAGES_DIR = "realImages"
JSON_DIR = "realImages_json"
MERGE_CACHE_FILE = "metadata_cache.json"

# KlasÃ¶rdeki dosyalarÄ±n hash'ini alalÄ±m
def get_file_hash(path):
    with open(path, "rb") as f:
        return hashlib.md5(f.read()).hexdigest()

def get_image_filenames():
    return sorted([f for f in os.listdir(REAL_IMAGES_DIR) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])

def get_json_hashes():
    hashes = {}
    for fname in ["yunportalclaude.json", "yunportalclaudedetail.json"]:
        path = os.path.join(JSON_DIR, fname)
        if os.path.exists(path):
            hashes[fname] = get_file_hash(path)
    return hashes

# KaydedilmiÅŸ cache dosyasÄ±nÄ± yÃ¼kle
def load_previous_cache():
    if not os.path.exists(MERGE_CACHE_FILE):
        return {"images": [], "json_hashes": {}}
    with open(MERGE_CACHE_FILE, "r", encoding="utf-8") as f:
        return json.load(f)

# GÃ¼ncel durumu kaydet
def save_current_cache(image_list, json_hashes):
    with open(MERGE_CACHE_FILE, "w", encoding="utf-8") as f:
        json.dump({"images": image_list, "json_hashes": json_hashes}, f, indent=2)

# Model dosyasÄ±nÄ± al
def get_model_data(model_type):
    model_path = os.path.join("exported_clusters", model_type, "versions.json")
    if not os.path.exists(model_path):
        return None
        
    try:
        with open(model_path, "r", encoding="utf-8") as f:
            return json.load(f)
    except:
        return None

# Mevcut clusterlarÄ± ve versiyonlarÄ± kontrol et
def check_cluster_integrity():
    # KullanÄ±labilir modelleri kontrol et
    models = ["pattern", "color", "texture"]
    updated = False
    
    for model in models:
        model_data = get_model_data(model)
        if not model_data:
            continue
        
        current_version = model_data.get("current_version")
        if not current_version:
            continue
            
        versions = model_data.get("versions", {})
        if not versions:
            continue
            
        # Metadata dosyasÄ±nÄ± yÃ¼kle
        metadata_path = "image_metadata_map.json"
        if not os.path.exists(metadata_path):
            continue
            
        with open(metadata_path, "r", encoding="utf-8") as f:
            metadata = json.load(f)
        
        # Versiyon tutarlÄ±lÄ±ÄŸÄ±nÄ± kontrol et
        for version_id, version_data in versions.items():
            clusters = version_data.get("clusters", {})
            for cluster_id, cluster_data in clusters.items():
                # Bu cluster'daki tÃ¼m gÃ¶rsellerin metadata'daki cluster bilgisini gÃ¼ncelle
                images = cluster_data.get("images", [])
                
                for image_name in images:
                    if image_name in metadata:
                        # Metadata bilgisini kontrol et ve gÃ¼ncelle
                        if metadata[image_name].get("cluster") != cluster_id:
                            metadata[image_name]["cluster"] = cluster_id
                            updated = True
                            print(f"ğŸ”„ GÃ¶rsel {image_name} iÃ§in cluster bilgisi gÃ¼ncellendi: {cluster_id}")
        
        # DeÄŸiÅŸiklik olduysa kaydet
        if updated:
            with open(metadata_path, "w", encoding="utf-8") as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
            print(f"âœ… Metadata tutarlÄ±lÄ±ÄŸÄ± saÄŸlandÄ±.")
    
    return updated

# AsÄ±l kontrol fonksiyonu
def check_for_updates():
    current_images = get_image_filenames()
    current_hashes = get_json_hashes()
    cached = load_previous_cache()
    
    # Ã–nce cluster tutarlÄ±lÄ±ÄŸÄ±nÄ± kontrol et
    cluster_updated = check_cluster_integrity()

    if cached["images"] != current_images or cached["json_hashes"] != current_hashes or cluster_updated:
        print("ğŸ”„ DeÄŸiÅŸiklik algÄ±landÄ±: metadata yeniden oluÅŸturuluyor...")
        import merge_metadata  # yeniden Ã§alÄ±ÅŸtÄ±r

        # Thumbnail'larÄ± da gÃ¼ncelle
        try:
            subprocess.run(["python", "generate_thumbnails.py"], check=True)
        except Exception as e:
            print(f"âŒ Thumbnail oluÅŸturma sÄ±rasÄ±nda hata: {e}")

        # âœ… GÃœNCELLEME: Cluster temsilcilerini de yeniden oluÅŸtur
        try:
            subprocess.run(["python", "generate_representatives.py"], check=True)
        except Exception as e:
            print(f"âŒ Cluster temsilcileri gÃ¼ncellenemedi: {e}")

        save_current_cache(current_images, current_hashes)
        return True
    else:
        print("âœ… DeÄŸiÅŸiklik yok, metadata gÃ¼ncel.")
        return False

if __name__ == "__main__":
    update_result = check_for_updates()
    print(f"ğŸ’¼ GÃ¼ncelleme durumu: {'GÃ¼ncellendi' if update_result else 'GÃ¼ncel'}")
