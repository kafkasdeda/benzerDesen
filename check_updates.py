# check_updates.py
# Bu dosya, realImages klasÃ¶rÃ¼ndeki gÃ¶rseller ve realImages_json iÃ§indeki JSON dosyalarÄ±nda bir deÄŸiÅŸiklik olup olmadÄ±ÄŸÄ±nÄ± kontrol eder.
# Yeni gÃ¶rseller veya gÃ¼ncellenmiÅŸ JSON tespit edilirse, kullanÄ±cÄ±ya detaylÄ± bilgi verir ve gerekli iÅŸlemlerin yapÄ±lmasÄ± iÃ§in onay bekler.
# OluÅŸturulma: 2025-04-19
# GÃ¼ncelleme: 2025-04-27 (KullanÄ±cÄ± onayÄ± eklendi)
# GÃ¼ncelleme: 2025-04-28 (Web arayÃ¼zÃ¼ entegrasyonu ve detaylÄ± deÄŸiÅŸiklik raporu eklendi)
# HazÄ±rlayan: Kafkas

import os
import time
import json
import hashlib
import subprocess
import pathlib
import shutil
from datetime import datetime
from merge_metadata import load_json

REAL_IMAGES_DIR = "realImages"
JSON_DIR = "realImages_json"
MERGE_CACHE_FILE = "metadata_cache.json"

# KlasÃ¶rdeki dosyalarÄ±n hash'ini alalÄ±m
def get_file_hash(path):
    with open(path, "rb") as f:
        return hashlib.md5(f.read()).hexdigest()

def get_image_filenames():
    return sorted([f for f in os.listdir(REAL_IMAGES_DIR) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])

def get_json_hashes():
    hashes = {}
    for fname in ["yunportalclaude.json", "yunportalclaudedetail.json"]:
        path = os.path.join(JSON_DIR, fname)
        if os.path.exists(path):
            hashes[fname] = get_file_hash(path)
    return hashes

# KaydedilmiÅŸ cache dosyasÄ±nÄ± yÃ¼kle
def load_previous_cache():
    if not os.path.exists(MERGE_CACHE_FILE):
        return {"images": [], "json_hashes": {}}
    with open(MERGE_CACHE_FILE, "r", encoding="utf-8") as f:
        return json.load(f)

# GÃ¼ncel durumu kaydet
def save_current_cache(image_list, json_hashes):
    with open(MERGE_CACHE_FILE, "w", encoding="utf-8") as f:
        json.dump({"images": image_list, "json_hashes": json_hashes}, f, indent=2)

# Model dosyasÄ±nÄ± al
def get_model_data(model_type):
    model_path = os.path.join("exported_clusters", model_type, "versions.json")
    if not os.path.exists(model_path):
        return None
        
    try:
        with open(model_path, "r", encoding="utf-8") as f:
            return json.load(f)
    except:
        return None

# Mevcut clusterlarÄ± ve versiyonlarÄ± kontrol et
def check_cluster_integrity():
    # KullanÄ±labilir modelleri kontrol et
    models = ["pattern", "color", "texture", "color+pattern"]
    updated = False
    updated_clusters = []
    
    # GÃ¼ncelleme bayraÄŸÄ±nÄ± kontrol et
    if os.path.exists('updating_clusters.flag'):
        print("âš ï¸ GÃ¼ncelleme iÅŸlemi devam ediyor, cluster kontrolÃ¼ atlanÄ±yor.")
        return False, []
    
    for model in models:
        model_data = get_model_data(model)
        if not model_data:
            continue
        
        current_version = model_data.get("current_version")
        if not current_version:
            continue
            
        versions = model_data.get("versions", {})
        if not versions:
            continue
            
        # Metadata dosyasÄ±nÄ± yÃ¼kle
        metadata_path = "image_metadata_map.json"
        if not os.path.exists(metadata_path):
            continue
            
        with open(metadata_path, "r", encoding="utf-8") as f:
            metadata = json.load(f)
        
        # Versiyon tutarlÄ±lÄ±ÄŸÄ±nÄ± kontrol et
        for version_id, version_data in versions.items():
            clusters = version_data.get("clusters", {})
            for cluster_id, cluster_data in clusters.items():
                # Bu cluster'daki tÃ¼m gÃ¶rsellerin metadata'daki cluster bilgisini gÃ¼ncelle
                images = cluster_data.get("images", [])
                
                for image_name in images:
                    if image_name in metadata:
                        # Metadata bilgisini kontrol et ve gÃ¼ncelle
                        if metadata[image_name].get("cluster") != cluster_id:
                            metadata[image_name]["cluster"] = cluster_id
                            updated = True
                            updated_clusters.append((image_name, cluster_id))
        
        # DeÄŸiÅŸiklik olduysa kaydet
        if updated:
            with open(metadata_path, "w", encoding="utf-8") as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)
    
    return updated, updated_clusters

# GÃ¶rsel meta bilgilerini getir
def get_image_metadata(image_name):
    # Metadata dosyasÄ±nÄ± kontrol et
    metadata_path = "image_metadata_map.json"
    if not os.path.exists(metadata_path):
        return {}
        
    try:
        with open(metadata_path, "r", encoding="utf-8") as f:
            metadata = json.load(f)
        
        return metadata.get(image_name, {})
    except Exception as e:
        print(f"Metadata okuma hatasÄ±: {e}")
        return {}

# GÃ¶rsel bilgilerini al
def get_image_info(image_name):
    image_path = os.path.join(REAL_IMAGES_DIR, image_name)
    if not os.path.exists(image_path):
        return {}
    
    # Dosya boyutu ve tarihi al
    file_stats = os.stat(image_path)
    file_size = file_stats.st_size
    created_time = datetime.fromtimestamp(file_stats.st_ctime).strftime('%Y-%m-%d %H:%M:%S')
    modified_time = datetime.fromtimestamp(file_stats.st_mtime).strftime('%Y-%m-%d %H:%M:%S')
    
    # GÃ¶rsel meta verileri
    metadata = get_image_metadata(image_name)
    
    return {
        "filename": image_name,
        "file_size": file_size,
        "file_size_formatted": format_file_size(file_size),
        "created": created_time,
        "modified": modified_time,
        "extension": pathlib.Path(image_name).suffix.lower(),
        "metadata": metadata
    }

# Dosya boyutunu formatlÄ± ÅŸekilde dÃ¶ndÃ¼r
def format_file_size(size_bytes):
    if size_bytes < 1024:
        return f"{size_bytes} B"
    elif size_bytes < 1024 * 1024:
        return f"{size_bytes / 1024:.1f} KB"
    elif size_bytes < 1024 * 1024 * 1024:
        return f"{size_bytes / (1024 * 1024):.1f} MB"
    else:
        return f"{size_bytes / (1024 * 1024 * 1024):.1f} GB"

# DeÄŸiÅŸiklikleri tespit et ve detaylÄ± rapor oluÅŸtur
def detect_changes():
    current_images = get_image_filenames()
    current_hashes = get_json_hashes()
    cached = load_previous_cache()
    
    # Ã–nce cluster tutarlÄ±lÄ±ÄŸÄ±nÄ± kontrol et
    cluster_updated, updated_clusters = check_cluster_integrity()

    # Yeni ve silinen gÃ¶rselleri tespit et
    new_images = [img for img in current_images if img not in cached["images"]]
    removed_images = [img for img in cached["images"] if img not in current_images]
    
    # JSON deÄŸiÅŸikliklerini tespit et
    json_changes = []
    for fname, current_hash in current_hashes.items():
        if fname not in cached["json_hashes"] or cached["json_hashes"][fname] != current_hash:
            json_changes.append(fname)
    
    # DeÄŸiÅŸiklik var mÄ± kontrol et
    has_changes = len(new_images) > 0 or len(removed_images) > 0 or len(json_changes) > 0 or cluster_updated
    
    # DetaylÄ± gÃ¶rsel bilgileri topla
    new_images_details = [get_image_info(img) for img in new_images]
    removed_images_details = [
        {
            "filename": img,
            "metadata": get_image_metadata(img)
        } for img in removed_images
    ]
    
    # Gereken iÅŸlemlerin listesini hazÄ±rla
    required_actions = []
    if new_images:
        required_actions.append({
            "action": "generate_thumbnails",
            "description": "Yeni gÃ¶rseller iÃ§in Ã¶nizleme oluÅŸtur"
        })
        required_actions.append({
            "action": "extract_features",
            "description": "Ã–zellik vektÃ¶rlerini gÃ¼ncelle"
        })
    
    if cluster_updated:
        required_actions.append({
            "action": "update_clusters",
            "description": "Cluster bilgilerini gÃ¼ncelle"
        })
    
    if json_changes:
        required_actions.append({
            "action": "update_metadata",
            "description": "Metadata bilgilerini gÃ¼ncelle"
        })
    
    # DeÄŸiÅŸiklik raporu oluÅŸtur
    change_report = {
        "has_changes": has_changes,
        "summary": {
            "new_images_count": len(new_images),
            "removed_images_count": len(removed_images),
            "json_changes_count": len(json_changes),
            "cluster_updates_count": len(updated_clusters) if cluster_updated else 0
        },
        "details": {
            "new_images": new_images_details,
            "removed_images": removed_images_details,
            "json_changes": json_changes,
            "cluster_updates": {
                "updated": cluster_updated,
                "details": updated_clusters
            }
        },
        "required_actions": required_actions,
        "current_images": current_images,
        "current_hashes": current_hashes,
        "timestamp": datetime.now().isoformat()
    }
    
    return change_report

# Gerekli gÃ¼ncellemeleri yap
def apply_updates(change_report):
    # Ä°ÅŸlemin baÅŸladÄ±ÄŸÄ±nÄ± gÃ¶steren bir flag dosyasÄ± oluÅŸtur
    with open('updating_clusters.flag', 'w') as f:
        f.write(datetime.now().isoformat())
        
    results = {
        "status": "success",
        "actions": [],
        "errors": []
    }
    
    # Metadata gÃ¼ncelleme
    try:
        import merge_metadata
        metadata_result = merge_metadata.merge_all_metadata()
        results["actions"].append({
            "action": "update_metadata",
            "status": "success",
            "message": "Metadata baÅŸarÄ±yla gÃ¼ncellendi"
        })
    except Exception as e:
        results["errors"].append({
            "action": "update_metadata",
            "error": str(e)
        })
        print(f"\nâŒ Metadata gÃ¼ncellenirken hata: {e}")

    # Yeni gÃ¶rseller iÃ§in thumbnail'larÄ± oluÅŸtur
    try:
        if len(change_report["details"]["new_images"]) > 0:
            subprocess.run(["python", "generate_thumbnails.py"], check=True)
            results["actions"].append({
                "action": "generate_thumbnails",
                "status": "success",
                "message": f"{len(change_report['details']['new_images'])} yeni gÃ¶rsel iÃ§in Ã¶nizleme oluÅŸturuldu"
            })
            print(f"\nâœ… {len(change_report['details']['new_images'])} yeni gÃ¶rsel iÃ§in Ã¶nizleme oluÅŸturuldu")
    except Exception as e:
        results["errors"].append({
            "action": "generate_thumbnails",
            "error": str(e)
        })
        print(f"\nâŒ Thumbnail oluÅŸturma sÄ±rasÄ±nda hata: {e}")

    # Ã–zellik vektÃ¶rlerini gÃ¼ncelle (tÃ¼m model tipleri iÃ§in)
    try:
        for model_type in ["pattern", "color", "texture", "color+pattern"]:
            subprocess.run(["python", "extract_features.py", "--model_type", model_type], check=True)
            results["actions"].append({
                "action": f"extract_features_{model_type}",
                "status": "success",
                "message": f"{model_type} modeli iÃ§in Ã¶zellik vektÃ¶rleri gÃ¼ncellendi"
            })
        print("\nâœ… TÃ¼m modeller iÃ§in Ã¶zellik vektÃ¶rleri baÅŸarÄ±yla gÃ¼ncellendi")
    except Exception as e:
        results["errors"].append({
            "action": "extract_features",
            "error": str(e)
        })
        print(f"\nâŒ Ã–zellik vektÃ¶rleri gÃ¼ncellenirken hata: {e}")

    # Cluster temsilcilerini de yeniden oluÅŸtur
    try:
        subprocess.run(["python", "generate_representatives.py"], check=True)
        results["actions"].append({
            "action": "generate_representatives",
            "status": "success",
            "message": "Cluster temsilcileri gÃ¼ncellendi"
        })
        print("\nâœ… Cluster temsilcileri gÃ¼ncellendi")
    except Exception as e:
        results["errors"].append({
            "action": "generate_representatives",
            "error": str(e)
        })
        print(f"\nâŒ Cluster temsilcileri gÃ¼ncellenemedi: {e}")

    # Faiss indekslerini temizle (gÃ¼ncelleme sonrasÄ± yeniden oluÅŸturmak iÃ§in)
    try:
        # app.py'de tanÄ±mlanan global faiss_indexes deÄŸiÅŸkenini sÄ±fÄ±rlamak iÃ§in bir dosya oluÅŸtur
        with open("reset_faiss_indexes.flag", "w") as f:
            f.write(datetime.now().isoformat())
        results["actions"].append({
            "action": "reset_faiss_indexes",
            "status": "success",
            "message": "Faiss indeksleri sÄ±fÄ±rlandÄ±"
        })
    except Exception as e:
        results["errors"].append({
            "action": "reset_faiss_indexes",
            "error": str(e)
        })

    # GÃ¼ncel durumu kaydet
    save_current_cache(change_report["current_images"], change_report["current_hashes"])
    
    # GÃ¼ncelleme tamamlandÄ±ÄŸÄ±nÄ± kaydeden dosya oluÅŸtur
    with open("updates_done.json", "w", encoding="utf-8") as f:
        update_record = {
            "timestamp": datetime.now().isoformat(),
            "status": results["status"],
            "summary": change_report.get("summary", {}),
            "actions": results["actions"]
        }
        json.dump(update_record, f, indent=2, ensure_ascii=False)
    
    # Flag dosyasÄ±nÄ± sil
    if os.path.exists('updating_clusters.flag'):
        os.remove('updating_clusters.flag')
    
    # BaÅŸarÄ± durumunu kontrol et
    if results["errors"]:
        results["status"] = "partial_success" if results["actions"] else "error"
    
    # Log dosyasÄ± oluÅŸtur
    update_log_path = f"update_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    with open(update_log_path, "w", encoding="utf-8") as f:
        update_log = {
            "timestamp": datetime.now().isoformat(),
            "changes": change_report,
            "results": results
        }
        json.dump(update_log, f, indent=2, ensure_ascii=False)
    
    print(f"\n{'âœ… GÃ¼ncellemeler baÅŸarÄ±yla tamamlandÄ±!' if results['status'] == 'success' else 'âš ï¸ BazÄ± gÃ¼ncellemeler tamamlanamadÄ±.'}")
    return results

# Ana kontrol fonksiyonu
def check_for_updates():
    # Ä°ÅŸlem zaten Ã§alÄ±ÅŸÄ±yorsa kontrolÃ¼ geÃ§
    if os.path.exists('updating_clusters.flag'):
        print("âš ï¸ GÃ¼ncelleme iÅŸlemi zaten devam ediyor.")
        
        # DosyanÄ±n 10 dakikadan daha eski olup olmadÄ±ÄŸÄ±nÄ± kontrol et
        flag_age = time.time() - os.path.getmtime('updating_clusters.flag')
        if flag_age > 600:  # 10 dakika (saniye cinsinden)
            print(f"ğŸ•‘ GÃ¼ncelleme bayraÄŸÄ± {flag_age/60:.1f} dakika eskide kalmÄ±ÅŸ, temizleniyor.")
            os.remove('updating_clusters.flag')
        else:
            # Ä°ÅŸlem devam ediyorsa boÅŸ sonuÃ§ dÃ¶ndÃ¼r
            return {
                "has_changes": False, 
                "message": "â³ GÃ¼ncelleme iÅŸlemi halen devam ediyor, lÃ¼tfen bekleyin.",
                "timestamp": datetime.now().isoformat()
            }
    
    # UygulanmÄ±ÅŸ gÃ¼ncellemelerin kaydÄ±nÄ± iÃ§eren dosya var mÄ±?
    updates_done_file = "updates_done.json"
    if os.path.exists(updates_done_file):
        try:
            with open(updates_done_file, "r", encoding="utf-8") as f:
                updates_done = json.load(f)
                last_update_time = datetime.fromisoformat(updates_done.get("timestamp", "2000-01-01T00:00:00"))
                current_time = datetime.now()
                
                # Son gÃ¼ncellemeden bu yana 2 saatten az zaman geÃ§tiyse ve zorla kontrol istenmemiÅŸse
                time_diff = (current_time - last_update_time).total_seconds()
                if time_diff < 7200:  # 2 saat
                    print(f"âœ… Son gÃ¼ncellemeden sadece {time_diff/60:.1f} dakika geÃ§ti.") 
                    return {
                        "has_changes": False, 
                        "message": f"âœ… Sistem gÃ¼ncel. Son gÃ¼ncelleme: {last_update_time.strftime('%Y-%m-%d %H:%M:%S')}",
                        "timestamp": current_time.isoformat()
                    }
        except Exception as e:
            print(f"UyarÄ±: GÃ¼ncelleme kaydÄ± okunamadÄ±: {e}")
            # Devam et ve gÃ¼ncellemeleri kontrol et
    
    # DeÄŸiÅŸiklikleri tespit et
    change_report = detect_changes()
    
    if change_report["has_changes"]:
        # DeÄŸiÅŸiklik raporu oluÅŸtur
        # KullanÄ±cÄ± arayÃ¼zÃ¼ iÃ§in friendly mesajlar
        notification_message = ""
        if change_report["summary"]["new_images_count"] > 0:
            notification_message += f"ğŸ“· {change_report['summary']['new_images_count']} yeni gÃ¶rsel eklendi. "  
        if change_report["summary"]["removed_images_count"] > 0:
            notification_message += f"ğŸš« {change_report['summary']['removed_images_count']} gÃ¶rsel silindi. "
        if change_report["summary"]["json_changes_count"] > 0:
            notification_message += f"ğŸ“ {change_report['summary']['json_changes_count']} JSON dosyasÄ± deÄŸiÅŸti. "  
        if change_report["summary"]["cluster_updates_count"] > 0:
            notification_message += f"ğŸ§¹ {change_report['summary']['cluster_updates_count']} cluster gÃ¼ncellendi. "
            
        change_report["notification"] = {
            "title": "GÃ¶rsel veya Metadata DeÄŸiÅŸikliÄŸi Tespit Edildi",
            "message": notification_message,
            "actions": [
                {
                    "action": "apply_updates",
                    "label": "GÃ¼ncelle",
                    "description": "TÃ¼m deÄŸiÅŸiklikleri uygula (thumbnail, Ã¶zellik vektÃ¶rleri, cluster bilgileri)"
                },
                {
                    "action": "ignore",
                    "label": "Yoksay",
                    "description": "DeÄŸiÅŸiklikleri yoksay (daha sonra tekrar hatÄ±rlatÄ±lacak)"
                },
                {
                    "action": "details",
                    "label": "DetaylarÄ± GÃ¶ster",
                    "description": "DeÄŸiÅŸikliklerin tam listesini gÃ¶ster"
                }
            ]
        }
        
        # Cache'i gÃ¼ncellememek iÃ§in Ã¶nceki dosyalarÄ± ve hashlarÄ± de ekle (eÄŸer ignore olursa)
        change_report["previous_cache"] = {
            "images": load_previous_cache()["images"],
            "json_hashes": load_previous_cache()["json_hashes"]
        }
        
        return change_report
    else:
        return {
            "has_changes": False, 
            "message": "âœ… DeÄŸiÅŸiklik yok, gÃ¶rsel ve metadata gÃ¼ncel.",
            "timestamp": datetime.now().isoformat()
        }

if __name__ == "__main__":
    report = check_for_updates()
    if report["has_changes"]:
        print("\nğŸ”” GÃ¶rsel veya metadata deÄŸiÅŸiklikleri algÄ±landÄ±!")
        
        if report["new_images"]:
            print(f"\nğŸ“· {len(report['new_images'])} yeni gÃ¶rsel eklendi:")
            for img in report["new_images"][:5]:
                print(f"  - {img}")
            if len(report["new_images"]) > 5:
                print(f"  - ... ve {len(report['new_images']) - 5} gÃ¶rsel daha")
                
        if report["removed_images"]:
            print(f"\nğŸš« {len(report['removed_images'])} gÃ¶rsel silindi veya taÅŸÄ±ndÄ±:")
            for img in report["removed_images"][:5]:
                print(f"  - {img}")
            if len(report["removed_images"]) > 5:
                print(f"  - ... ve {len(report['removed_images']) - 5} gÃ¶rsel daha")
        
        if report["json_changes"]:
            print(f"\nğŸ“ {len(report['json_changes'])} metadata dosyasÄ± deÄŸiÅŸtirildi:")
            for json_file in report["json_changes"]:
                print(f"  - {json_file}")
        
        if report["cluster_updates"]["updated"]:
            print(f"\nğŸ§¹ Cluster bilgileri gÃ¼ncellendi")
            for img, cluster in report["cluster_updates"]["details"][:5]:
                print(f"  - {img} â†’ {cluster}")
            if len(report["cluster_updates"]["details"]) > 5:
                print(f"  - ... ve {len(report['cluster_updates']['details']) - 5} gÃ¶rsel daha")
        
        choice = input("\nğŸ‘©â€ğŸ’» Bu deÄŸiÅŸikliklere dayalÄ± olarak gerekli gÃ¼ncellemeleri yapmak istiyor musunuz? (E/H): ")
        if choice.lower() == "e":
            print("\nğŸ”„ GÃ¼ncellemeler yapÄ±lÄ±yor...")
            apply_updates(report)
        else:
            print("\nâ„¹ï¸ GÃ¼ncelleme iÅŸlemi iptal edildi. DeÄŸiÅŸiklikler kaydedilmedi.")
    else:
        print(report["message"])