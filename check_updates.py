# check_updates.py
# Bu dosya, realImages klasÃ¶rÃ¼ndeki gÃ¶rseller ve realImages_json iÃ§indeki JSON dosyalarÄ±nda bir deÄŸiÅŸiklik olup olmadÄ±ÄŸÄ±nÄ± kontrol eder.
# Yeni gÃ¶rseller veya gÃ¼ncellenmiÅŸ JSON tespit edilirse, merge_metadata.py fonksiyonu tetiklenerek metadata yeniden oluÅŸturulur.
# OluÅŸturulma: 2025-04-19
# HazÄ±rlayan: Kafkas 

# realImages/ klasÃ¶rÃ¼ndeki gÃ¶rsellerin adlarÄ±nÄ± alÄ±r

# realImages_json/yunportalclaude.json ve yunportalclaudedetail.json dosyalarÄ±nÄ±n hash'ini alÄ±r

# Daha Ã¶nceki durumu metadata_cache.json iÃ§inde tutar

# GÃ¶rseller deÄŸiÅŸtiyse veya JSONâ€™lar gÃ¼ncellendiyse:

# ğŸ”„ merge_metadata.py dosyasÄ±nÄ± otomatik Ã§alÄ±ÅŸtÄ±rÄ±r

# Cache dosyasÄ±nÄ± gÃ¼nceller



import os
import time
import json
import hashlib
from merge_metadata import load_json

REAL_IMAGES_DIR = "realImages"
JSON_DIR = "realImages_json"
MERGE_CACHE_FILE = "metadata_cache.json"

# KlasÃ¶rdeki dosyalarÄ±n hash'ini alalÄ±m
def get_file_hash(path):
    with open(path, "rb") as f:
        return hashlib.md5(f.read()).hexdigest()

def get_image_filenames():
    return sorted([f for f in os.listdir(REAL_IMAGES_DIR) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])

def get_json_hashes():
    hashes = {}
    for fname in ["yunportalclaude.json", "yunportalclaudedetail.json"]:
        path = os.path.join(JSON_DIR, fname)
        if os.path.exists(path):
            hashes[fname] = get_file_hash(path)
    return hashes

# KaydedilmiÅŸ cache dosyasÄ±nÄ± yÃ¼kle
def load_previous_cache():
    if not os.path.exists(MERGE_CACHE_FILE):
        return {"images": [], "json_hashes": {}}
    with open(MERGE_CACHE_FILE, "r", encoding="utf-8") as f:
        return json.load(f)

# GÃ¼ncel durumu kaydet
def save_current_cache(image_list, json_hashes):
    with open(MERGE_CACHE_FILE, "w", encoding="utf-8") as f:
        json.dump({"images": image_list, "json_hashes": json_hashes}, f, indent=2)

# AsÄ±l kontrol fonksiyonu
def check_for_updates():
    current_images = get_image_filenames()
    current_hashes = get_json_hashes()
    cached = load_previous_cache()

    if cached["images"] != current_images or cached["json_hashes"] != current_hashes:
        print("ğŸ”„ DeÄŸiÅŸiklik algÄ±landÄ±: metadata yeniden oluÅŸturuluyor...")
        import merge_metadata  # yeniden Ã§alÄ±ÅŸtÄ±r
        save_current_cache(current_images, current_hashes)
        return True
    else:
        print("âœ… DeÄŸiÅŸiklik yok, metadata gÃ¼ncel.")
        return False

if __name__ == "__main__":
    check_for_updates()
