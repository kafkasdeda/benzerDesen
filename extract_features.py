# extract_features.py
# OluÅŸturulma: 2025-04-19
# GÃ¼ncelleme: Renk + Desen modeli eklendi
# HazÄ±rlayan: Kafkas
# AÃ§Ä±klama:
# Bu script, realImages/ klasÃ¶rÃ¼ndeki tÃ¼m gÃ¶rselleri iÅŸler,
# model tÃ¼rÃ¼ne (desen, renk, doku, renk+desen) gÃ¶re uygun ÅŸekilde dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r,
# pretrained ResNet18 ile feature vektÃ¶rlerini Ã§Ä±karÄ±r,
# image_features klasÃ¶rÃ¼ne .npy ve .json dosyalarÄ± olarak kaydeder.

import os
import json
import torch
import numpy as np
from torchvision import models, transforms
from PIL import Image
from tqdm import tqdm
import argparse

# Komut satÄ±rÄ± parametrelerini ayarla
parser = argparse.ArgumentParser(description="GÃ¶rsel Ã¶zellik Ã§Ä±karÄ±m aracÄ±")
parser.add_argument("--model_type", type=str, default="pattern", 
                    choices=["pattern", "color", "texture", "color+pattern"],
                    help="Model tÃ¼rÃ¼: pattern, color, texture veya color+pattern")
args = parser.parse_args()

# GiriÅŸ klasÃ¶rÃ¼ ve model tÃ¼rÃ¼
INPUT_FOLDER = "realImages"
MODEL_TYPE = args.model_type  # pattern / color / texture / color+pattern

# Ã‡Ä±kÄ±ÅŸ yollarÄ±
os.makedirs("image_features", exist_ok=True)
feature_out = f"image_features/{MODEL_TYPE}_features.npy"
filenames_out = f"image_features/{MODEL_TYPE}_filenames.json"

# GPU kullanÄ±labiliyorsa aktif et
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ResNet18 yÃ¼klÃ¼yoruz (son katmanÄ± kullanmÄ±yoruz)
model = models.resnet18(pretrained=True)
model = torch.nn.Sequential(*list(model.children())[:-1])
model.to(device)
model.eval()

# Model tÃ¼rÃ¼ne gÃ¶re transform ayarÄ±
if MODEL_TYPE == "pattern":
    transform = transforms.Compose([
        transforms.Grayscale(num_output_channels=3),
        transforms.Resize((224, 224)),
        transforms.ToTensor()
    ])
elif MODEL_TYPE == "color":
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor()
    ])
elif MODEL_TYPE == "texture":
    transform = transforms.Compose([
        transforms.Grayscale(num_output_channels=3),
        transforms.Resize((224, 224)),
        transforms.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 2.0)),
        transforms.ToTensor()
    ])
elif MODEL_TYPE == "color+pattern":
    # Renk + Desen iÃ§in her iki Ã¶zelliÄŸi de iÅŸliyoruz
    # Ã–nce ayrÄ± ayrÄ± Ã¶zellikleri Ã§Ä±karÄ±p sonra birleÅŸtireceÄŸiz
    transform_color = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor()
    ])
    transform_pattern = transforms.Compose([
        transforms.Grayscale(num_output_channels=3),
        transforms.Resize((224, 224)),
        transforms.ToTensor()
    ])
    # Ana transform kullanmayacaÄŸÄ±z, iki modeli ayrÄ± uygulayacaÄŸÄ±z
    transform = None
else:
    raise ValueError("GeÃ§ersiz MODEL_TYPE")

features = []
image_paths = []

print(f"ğŸ“¬ {MODEL_TYPE} modÃ¼lÃ¼ iÃ§in gÃ¶rsel Ã¶zellikler Ã§Ä±karÄ±lÄ±yor...")

if MODEL_TYPE == "color+pattern":
    # Renk + Desen iÃ§in Ã¶zel iÅŸlem
    for fname in tqdm(os.listdir(INPUT_FOLDER)):
        if not fname.lower().endswith(('.jpg', '.jpeg', '.png')):
            continue

        fpath = os.path.join(INPUT_FOLDER, fname)
        try:
            img = Image.open(fpath).convert("RGB")
            
            # Renk Ã¶zelliklerini Ã§Ä±kar
            img_color = transform_color(img).unsqueeze(0).to(device)
            with torch.no_grad():
                vec_color = model(img_color).squeeze().cpu().numpy()
                
            # Desen Ã¶zelliklerini Ã§Ä±kar
            img_pattern = transform_pattern(img).unsqueeze(0).to(device)
            with torch.no_grad():
                vec_pattern = model(img_pattern).squeeze().cpu().numpy()
            
            # Ä°ki Ã¶zellik vektÃ¶rÃ¼nÃ¼ birleÅŸtir
            # SÄ±rayla birleÅŸtirme (concatenate)
            combined_vec = np.concatenate([vec_color, vec_pattern])
            
            features.append(combined_vec)
            image_paths.append(os.path.basename(fpath))
        except Exception as e:
            print(f"âš ï¸ Hata: {fname} atlandÄ±. {e}")
else:
    # Normal modeller iÃ§in standart iÅŸlem
    for fname in tqdm(os.listdir(INPUT_FOLDER)):
        if not fname.lower().endswith(('.jpg', '.jpeg', '.png')):
            continue

        fpath = os.path.join(INPUT_FOLDER, fname)
        try:
            img = Image.open(fpath).convert("RGB")
            img_t = transform(img).unsqueeze(0).to(device)

            with torch.no_grad():
                vec = model(img_t).squeeze().cpu().numpy()
                features.append(vec)
                image_paths.append(os.path.basename(fpath))
        except Exception as e:
            print(f"âš ï¸ Hata: {fname} atlandÄ±. {e}")

# KayÄ±t
np.save(feature_out, np.array(features))
with open(filenames_out, "w", encoding="utf-8") as f:
    json.dump(image_paths, f, indent=2)

feature_dim = features[0].shape[0] if features else 0
print(f"âœ… {len(features)} gÃ¶rsel iÃ§in {MODEL_TYPE} Ã¶zellik Ã§Ä±karÄ±mÄ± tamamlandÄ±.")
print(f"Her gÃ¶rsel iÃ§in Ã¶zellik boyutu: {feature_dim}")
