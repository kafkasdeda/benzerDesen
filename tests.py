import torch
import torch.nn as nn
import torch.optim as optim
import time

# Rastgele veri seti oluÅŸtur (1000 Ã¶rnek, her biri 100 Ã¶zellikli, 10 sÄ±nÄ±f)
num_samples = 1000
num_features = 100
num_classes = 10

X = torch.randn(num_samples, num_features)
y = torch.randint(0, num_classes, (num_samples,))

# Basit bir MLP modeli
class SimpleNet(nn.Module):
    def __init__(self):
        super(SimpleNet, self).__init__()
        self.fc1 = nn.Linear(num_features, 256)
        self.relu = nn.ReLU()
        self.fc2 = nn.Linear(256, num_classes)

    def forward(self, x):
        return self.fc2(self.relu(self.fc1(x)))

def train(model, device):
    model.to(device)
    X_dev = X.to(device)
    y_dev = y.to(device)

    criterion = nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)

    start = time.time()
    for epoch in range(10):  # 10 epoch eÄŸitim
        optimizer.zero_grad()
        outputs = model(X_dev)
        loss = criterion(outputs, y_dev)
        loss.backward()
        optimizer.step()
    if device.type == 'cuda':
        torch.cuda.synchronize()
    end = time.time()
    return end - start

# CPU'da eÄŸitim
model_cpu = SimpleNet()
cpu_time = train(model_cpu, torch.device('cpu'))
print(f"ğŸ§  CPU ile eÄŸitim sÃ¼resi: {cpu_time:.4f} saniye")

# GPU varsa eÄŸitim
if torch.cuda.is_available():
    model_gpu = SimpleNet()
    gpu_time = train(model_gpu, torch.device('cuda'))
    print(f"âš¡ GPU ile eÄŸitim sÃ¼resi: {gpu_time:.4f} saniye")
else:
    print("âš ï¸ GPU bulunamadÄ±, GPU testi atlandÄ±.")
